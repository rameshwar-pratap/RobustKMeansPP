{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file consists of implementation of “Robust k-means++” paper. \n",
    "Author: Praneeth Kacham\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import statistics\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq_distance(x,y):\n",
    "    diff = x-y\n",
    "    return np.inner(diff,diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest(distances, num_outliers):\n",
    "    \"\"\"Takes the distances array and returns indices of the farthest 'num_outliers' and indices of remaining points using these distances\"\"\"\n",
    "    idx = np.argpartition(distances,-num_outliers)\n",
    "    return idx[-num_outliers:],idx[:-num_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeanspp(points,k):\n",
    "    \"\"\"\n",
    "    points - nxd array of points\n",
    "    k - number of clusters\n",
    "    \"\"\"\n",
    "    m,_ = points.shape\n",
    "    center_indices = [np.random.choice(m)]\n",
    "    c_point = points[center_indices[0]]\n",
    "    sq_distances = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        sq_distances[i] = sq_distance(points[i],c_point)\n",
    "    for i in range(k-1):\n",
    "        sum_ = np.sum(sq_distances)\n",
    "        prob = sq_distances/sum_\n",
    "        c_index = np.random.choice(np.arange(m),1,p=prob)\n",
    "        center_indices.append(c_index[0])\n",
    "        c_point = points[c_index]\n",
    "        for j in range(m):\n",
    "            c_dist = sq_distance(points[j],c_point)\n",
    "            if( c_dist < sq_distances[j]):\n",
    "                sq_distances[j] = np.float(c_dist)\n",
    "    return center_indices, sq_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_initialization(points,k):\n",
    "    \"\"\"\n",
    "    points - nxd array\n",
    "    k : int - number of clusters\n",
    "    \"\"\"\n",
    "    center_indices = np.random.choice(np.arange(len(points)),k,replace=False)\n",
    "    sq_distances = [min([sq_distance(point, points[center]) for center in center_indices]) for point in points]\n",
    "    return center_indices, sq_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points,center_indices):\n",
    "    \"\"\"\n",
    "    points - nxd array\n",
    "    center_indices : [int] \n",
    "    \"\"\"\n",
    "    m,_ = points.shape\n",
    "    cost = sum([min([sq_distance(points[i],points[center_index]) for center_index in center_indices]) for i in range(m)])\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the probability of picking each point\n",
    "def mixture_sampling(points,center_indices,alpha,distances_squared):\n",
    "    \"\"\"\n",
    "    points : mxd array of points\n",
    "    center_indices : [int]\n",
    "    alpha : float\n",
    "    distances_squared : [float] of size m\n",
    "    \"\"\"\n",
    "# alpha is the coefficient of Uniform Sampling. If alpha = 0, then k-means++ if alpha = 1, then uniform\n",
    "    m = len(points)\n",
    "    total_distances_squared = sum(distances_squared)\n",
    "    probabilities = [(1-alpha)*x/total_distances_squared + alpha/m for x in distances_squared]\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_with_mixture(points,k,delta,alpha):\n",
    "    \"\"\"\n",
    "    points : mxd array \n",
    "    k : int - number of clusters\n",
    "    delta : float\n",
    "    alpha : float\n",
    "    \n",
    "    Returns : \n",
    "    center_indices : 1 + (k-1)/delta size array of ints\n",
    "    cluster_number : [int] of size m : cluster_number[i] denotes the index of the nearest point in center_indices\n",
    "    distances : [float] of size m : distance to nearest cluster center\n",
    "    \"\"\"\n",
    "    m,_ = points.shape\n",
    "    distances = np.zeros(m)\n",
    "    center_indices = [np.random.choice(m)] #np.random.c #Choosing first centre randomly\n",
    "    cluster_number = [center_indices[0] for i in range(m)]\n",
    "    for i in range(m):\n",
    "        distances[i] = sq_distance(points[i],points[center_indices[0]])\n",
    "    for i in range(k-1): # Choosing 1/delta centres from mixture distribution in each iteration\n",
    "        probabilities = mixture_sampling(points,center_indices,alpha,distances)\n",
    "        a = np.random.choice(np.arange(m),int(1/delta),p=probabilities)\n",
    "        a = list(set(a))\n",
    "        center_indices.extend(a)\n",
    "        for j in range(m):\n",
    "            for new in a:\n",
    "                dist = sq_distance(points[j],points[new])\n",
    "                if (dist < distances[j]):\n",
    "                    cluster_number[j] = new\n",
    "                    distances[j] = dist\n",
    "    return center_indices, cluster_number, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_of_clusters(points, center_indices, cluster_number):\n",
    "    \"\"\"\n",
    "    points : mxd array\n",
    "    center_indices : [int] - list of indices of centres\n",
    "    cluster_number : [int] - index of nearest centre to each point\n",
    "    \n",
    "    Returns:\n",
    "    weights : dictionary : center_indices -> int : Take care that each value is non-zero\n",
    "    \"\"\"\n",
    "    weights = {}\n",
    "    for index in center_indices:\n",
    "        weights[index] = 0\n",
    "    for i in range(len(cluster_number)):\n",
    "        weights[cluster_number[i]] += 1\n",
    "    for index in center_indices:\n",
    "        if weights[index] == 0:\n",
    "            print(\"Error : The following index is not closest to any\")\n",
    "            print(index)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_probabilities(points, indices, centers, weights):\n",
    "    \"\"\"\n",
    "    Returns the probabilities for weighted D^2 sampling given the current centers\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    for i in range(len(indices)):\n",
    "        current_point = points[indices[i]]\n",
    "        current_weight = weights[indices[i]] \n",
    "        min_weighted_distance = float(\"inf\")\n",
    "        for j in centers:\n",
    "            center_point = points[j]\n",
    "            weighted_distance_square = current_weight*np.dot(center_point-current_point,center_point-current_point)\n",
    "            if weighted_distance_square < min_weighted_distance:\n",
    "                min_weighted_distance = weighted_distance_square\n",
    "        costs.append(min_weighted_distance)\n",
    "    total_dis_squared = sum(costs)\n",
    "    probs = [cost/total_dis_squared for cost in costs]\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_kmeans(points,indices,weights,k,repetitions=100):\n",
    "    \"\"\"\n",
    "    Given the points, indices which should be considered for clustering, weights of each points, k, performs many repetitions\n",
    "    of weighted_kmeans and returns the best weighted clustering\n",
    "    \"\"\"\n",
    "    current_cost = np.float(\"inf\")\n",
    "    best_centers = []\n",
    "    for rep in range(repetitions):\n",
    "        centers = (np.random.choice(indices,1))\n",
    "        centers = centers.tolist()\n",
    "        for i in range(k-1):\n",
    "            probabilities = weighted_probabilities(points,indices,centers,weights)\n",
    "            centers.extend((np.random.choice(indices,1,p=probabilities)).tolist())\n",
    "        cost = 0\n",
    "        for i in range(len(indices)):\n",
    "            nearest_distance = float(\"inf\")\n",
    "            for j in centers:\n",
    "                if sq_distance(points[j],points[indices[i]]) < nearest_distance:\n",
    "                    nearest_distance = sq_distance(points[indices[i]],points[j])\n",
    "            cost += nearest_distance*weights[indices[i]]\n",
    "        if(cost < current_cost):\n",
    "            best_centers = centers\n",
    "            current_cost = cost\n",
    "    return best_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_gaussian(k, num_points, num_outliers, dimension, inlier_box, outlier_box):\n",
    "    \"\"\"\n",
    "    Generates k cluster_centres, each with num_points/k points chosen with gaussian distribution of unit variance around the cluster centre.\n",
    "    Additionally adds num_outliers number of random points within the outlier_box. Then finds the true_outliers as the farthest num_outliers no. of points\n",
    "    from cluster_centres\n",
    "    \"\"\"\n",
    "    num_repeats = int(num_points/k)\n",
    "    points = []\n",
    "    cov = np.ones(dimension)\n",
    "    cov = np.diag(cov)\n",
    "    centers = []\n",
    "    cost = 0.0\n",
    "    for i in range(k):\n",
    "        current = np.random.uniform(0,inlier_box,dimension)\n",
    "        centers.append(current)\n",
    "        new_points = np.random.multivariate_normal(current,cov,num_repeats).tolist()\n",
    "        for point in new_points:\n",
    "            cost += sq_distance(point,current)\n",
    "        points.extend(new_points)\n",
    "    lb = -1.0*(outlier_box - inlier_box)/2.0\n",
    "    ub = inlier_box + (outlier_box - inlier_box)/2.0\n",
    "    for i in range(num_outliers):\n",
    "        current = np.random.uniform(lb,ub,dimension)\n",
    "        points.append(current)\n",
    "    points = np.array(points)\n",
    "    m,_ = points.shape\n",
    "    distances = [] # Denotes the distance to the nearest cluster center\n",
    "    cluster = [] # Denotes the cluster to which the point belongs\n",
    "    for i in range(m):\n",
    "        distance = min([(sq_distance(points[i],centers[j]),j) for j in range(len(centers))])\n",
    "        distances.append((distance[0],i))\n",
    "        cluster.append(distance[1])\n",
    "    distances.sort()\n",
    "    true_outliers = [a[1] for a in distances[-1*num_outliers:]]\n",
    "    for j in true_outliers:\n",
    "        cluster[j] = -1\n",
    "    return points, true_outliers, cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(cluster_indices,inliers): #Cluster center of cluster to which a point belongs to\n",
    "    \"\"\"\n",
    "    Finds the weights of each of the points i.e., no. of points for which this is the closest point in chosen centres\n",
    "    \"\"\"\n",
    "    w = {}\n",
    "    for i in inliers:\n",
    "        if cluster_indices[i] not in w:\n",
    "            w[cluster_indices[i]] = 0\n",
    "        w[cluster_indices[i]] += 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_cost(points,center_indices,num_outliers):\n",
    "    \"\"\"\n",
    "    Finds the cost of the kmeans solution excluding farthest num_outliers no. of points\n",
    "    \"\"\"\n",
    "    m,_ = points.shape\n",
    "    distances = []\n",
    "    for i in range(m):\n",
    "        distances.append((min([sq_distance(points[i],points[j]) for j in center_indices]),i))\n",
    "    distances.sort()\n",
    "    farthest = distances[-1*num_outliers:]\n",
    "    return (sum([dist[0] for dist in farthest]),[dist[1] for dist in farthest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_from_centres(points, centre_indices):\n",
    "    distances = [min([sq_distance(points[i],points[centre_index]) for centre_index in centre_indices]) for i in range(len(points))]\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_kmeanspp(data, k, num_outliers, alpha, delta, true_outliers, repetitions):\n",
    "    outliers_recovereds = []\n",
    "    costs = []\n",
    "    for rep in range(repetitions):\n",
    "        # First we select k/delta points using kmeans_with_mixture\n",
    "        initial_centres, clusters, distances = kmeans_with_mixture(data, k, delta, alpha)\n",
    "        # Now find farthest \"num_outliers\" \n",
    "        initial_outliers, initial_inliers = farthest(distances, num_outliers)\n",
    "        # Now find weights of clusters\n",
    "        weights_of_clusters = weights(clusters, initial_inliers)\n",
    "        # The following heuristic can be used to remove the centres which have low weight.\n",
    "#         to_remove = []\n",
    "#         for i in initial_centres:\n",
    "#             if weights_of_clusters[i] == 1:\n",
    "#                 to_remove.append(i)\n",
    "#         initial_centres = list(set(initial_centres)-set(to_remove))\n",
    "        weighted_kmeans_results = weighted_kmeans(data, initial_centres, weights_of_clusters,k,60)\n",
    "        # Now, we have k centres. Remove farthest \"num_outliers\" from these k centres\n",
    "        distances_from_final_centres = distance_from_centres(data, weighted_kmeans_results)\n",
    "        outliers,inliers = farthest(distances_from_final_centres,num_outliers)\n",
    "        kmeans = KMeans(n_clusters=k,init=data[weighted_kmeans_results],n_init=1).fit(data[inliers])\n",
    "        cost = kmeans.inertia_\n",
    "        predicted_outliers = outliers\n",
    "        outliers_recovered = len(set(predicted_outliers) & set(true_outliers))\n",
    "        outliers_recovereds.append(outliers_recovered)\n",
    "        costs.append(cost)\n",
    "    average_outliers_recovered = statistics.mean(outliers_recovereds)\n",
    "    max_outliers_recovered = max(outliers_recovereds)\n",
    "    median_outliers_recovered = statistics.median(outliers_recovereds)\n",
    "    average_cost = statistics.mean(costs)\n",
    "    median_cost = statistics.median(costs)\n",
    "    min_cost = min(costs)\n",
    "    return (max_outliers_recovered, average_outliers_recovered, median_outliers_recovered, min_cost, average_cost, median_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeanspp_outliers(data, k, num_outliers, true_outliers, repetitions):\n",
    "    m,_ = data.shape\n",
    "    outliers_recovereds = []\n",
    "    costs = []\n",
    "    for rep in range(repetitions):\n",
    "        centres = [np.random.choice(m)]\n",
    "        distances = np.array([sq_distance(data[i],data[centres[0]]) for i in range(m)])\n",
    "        clusters = [centres[0] for i in range(m)]\n",
    "        for i in range(k-1):\n",
    "            distance_sum = np.sum(distances)\n",
    "            probabilities = [distances[i]/distance_sum for i in range(m)]\n",
    "            c_index = np.random.choice(np.arange(m),1,p=probabilities)\n",
    "            centres.append(c_index[0])\n",
    "            for j in range(m):\n",
    "                distance_from_new_centre = sq_distance(data[c_index,:], data[j,:])\n",
    "                if distance_from_new_centre < distances[j]:\n",
    "                    distances[j] = distance_from_new_centre\n",
    "                    clusters[j] = c_index\n",
    "        outliers, inliers = farthest(distances, num_outliers)\n",
    "        # Now run lloyd's on the remaining points\n",
    "        kmeans = KMeans(n_clusters=k,init=data[centres],n_init=1).fit(data[inliers])\n",
    "        cost = kmeans.inertia_\n",
    "        outliers_recovered = len(set(true_outliers)&set(outliers))\n",
    "        outliers_recovereds.append(outliers_recovered)\n",
    "        costs.append(cost)\n",
    "    average_outliers_recovered = statistics.mean(outliers_recovereds)\n",
    "    max_outliers_recovered = max(outliers_recovereds)\n",
    "    median_outliers_recovered = statistics.median(outliers_recovereds)\n",
    "    average_cost = statistics.mean(costs)\n",
    "    median_cost = statistics.median(costs)\n",
    "    min_cost = min(costs)\n",
    "    return (max_outliers_recovered, average_outliers_recovered, median_outliers_recovered, min_cost, average_cost, median_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_outliers(data, k, num_outliers, true_outliers, repetitions):\n",
    "    m,_ = data.shape\n",
    "    outliers_recovereds = []\n",
    "    costs = []\n",
    "    for rep in range(repetitions):\n",
    "        centres = np.random.choice(np.arange(m),k,replace=False)\n",
    "        distances = [min([sq_distance(data[i],data[centre]) for centre in centres]) for i in range(m)]\n",
    "        outliers,inliers = farthest(distances, num_outliers)\n",
    "        kmeans = KMeans(n_clusters=k, init=data[centres], n_init=1).fit(data[inliers])\n",
    "        cost = kmeans.inertia_\n",
    "        outliers_recovered = len(set(true_outliers)&set(outliers))\n",
    "        costs.append(cost)\n",
    "        outliers_recovereds.append(outliers_recovered)\n",
    "    average_outliers_recovered = statistics.mean(outliers_recovereds)\n",
    "    max_outliers_recovered = max(outliers_recovereds)\n",
    "    median_outliers_recovered = statistics.median(outliers_recovereds)\n",
    "    average_cost = statistics.mean(costs)\n",
    "    median_cost = statistics.median(costs)\n",
    "    min_cost = min(costs)\n",
    "    return (max_outliers_recovered, average_outliers_recovered, median_outliers_recovered, min_cost, average_cost, median_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiments --  Real world Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fileName):\n",
    "    with open(fileName) as file:\n",
    "        readCSV = csv.reader(file,delimiter=' ')\n",
    "        examples = []\n",
    "        labels = []\n",
    "        for row in readCSV:\n",
    "            current = [float(x) for x in row[:-1]]\n",
    "            labels.append(int(row[-1]))\n",
    "            examples.append(current)\n",
    "        examples = np.array(examples)\n",
    "        labels = np.array(labels)\n",
    "        return(examples,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples,labels = read_data(filename) ## Inout the file name of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for (k,outliers) in [(5,17),(5,21),(10,17),(10,34),(15,17),(15,51)]:\n",
    "    result = kmeanspp_outliers(examples, k, outliers, true_outliers, 10)\n",
    "    results[(k,outliers)] = result\n",
    "    print((k,outliers))\n",
    "    print((result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means++ = (32, 30, 30.0, 11686.977635238474, 12647.745659383, 12647.745659383)\n",
      "random = (31, 23, 23.0, 12109.216490527706, 25005.299295364595, 25005.299295364595)\n",
      "delta = 0.05 alpha = 0 (63, 60, 60.0, 4168.902434899326, 5475.688855591797, 5475.688855591797)\n",
      "delta = 0.05 alpha = 0.25 (51, 45, 45.0, 6069.304794657046, 7542.132125319416, 7542.132125319416)\n",
      "delta = 0.05 alpha = 0.5 (60, 55, 55.0, 4366.655562256535, 5527.807565686766, 5527.807565686766)\n",
      "delta = 0.05 alpha = 0.75 (72, 61, 61.0, 2789.463430399758, 4758.591013713041, 4758.591013713041)\n",
      "delta = 0.05 alpha = 1 (71, 66.5, 66.5, 2861.4149113447315, 2998.5306503623915, 2998.5306503623915)\n",
      "delta = 0.1 alpha = 0 (62, 58, 58.0, 4466.805352190808, 4482.477553904404, 4482.477553904404)\n",
      "delta = 0.1 alpha = 0.25 (50, 46, 46.0, 4593.837460237914, 6033.249642184691, 6033.249642184691)\n",
      "delta = 0.1 alpha = 0.5 (61, 52.5, 52.5, 4144.608781037582, 5674.432399121444, 5674.432399121444)\n",
      "delta = 0.1 alpha = 0.75 (62, 60, 60.0, 4241.435289346939, 4316.576908045647, 4316.576908045647)\n",
      "delta = 0.1 alpha = 1 (88, 82, 82.0, 1888.9759809873703, 2332.7528158273476, 2332.7528158273476)\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "d = 2\n",
    "k = 20\n",
    "inbox = 100\n",
    "outbox = 100\n",
    "outliers = 100\n",
    "data, true_outliers, cluster = generate_data_gaussian(k, n, outliers, d, inbox, outbox)\n",
    "results = kmeanspp_outliers(data, k, outliers, true_outliers, 2)\n",
    "print(\"k-means++ = \"+str(results))\n",
    "results = random_outliers(data, k, outliers, true_outliers, 2)\n",
    "print(\"random = \"+str(results))\n",
    "for delta in [0.05, 0.1]:\n",
    "    for alpha in [0, 0.25, 0.5, 0.75, 1]:\n",
    "        results = robust_kmeanspp(data, k, outliers, alpha, delta, true_outliers, 2)\n",
    "        print(\"delta = \"+str(delta)+\" alpha = \"+str(alpha)+\" \"+str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
